---
layout : posts
published : true
--- 

# 토큰화하는 방법

이전 장에서 토큰화가 무엇인지 알아봤다. 우리는 산업역군의 프로그래머이기 때문에 실제 구현가능한 형태를 원한다.

예제: flex 를 이용해서 간단히 토큰화를 어떻게 하는지 살펴보겠다. 

flex 가 무엇인지 살펴보면

>flex는 《fast lexical analyzer generator》의 줄임말로 lex의 기능을 개선한 자유 소프트웨어이다. 주로 bison과 쌍을 이루어 구문 분석기를 만드는 데 사용된다. flex를 이용하면 C로 구문 문석 코드를 만들 수 있다. 한편 C++ 코드를 만들어 주는 비슷한 기능을 하는 프로그램으로 flex++가 있으며 flex와 함께 배포된다. 작성자는 "Vern Paxson"씨로 1987년도에 처음 만들어졌다.

앞 장에서 봤듯 입력된 문법이 적법한지 상관없이 어떤 종류의 문자열인가를 판단하는 1차 분류로 생각하면 된다.

```
%{
  Prologue
%} 
Bison declarations 
%%
Grammar rules
%% 
Epilogue
```

구조는 위와 같은데, 우리는 마지막 Epilogue 는 쓰지 않을 것이다. 처음 %{ ... %} 사이에는 include 문들이 오고, Bison declarations 에는 flex 가 해당 문법파일을 어떻게 컴파일할것인지 옵션이 담긴다. 다음으로 Grammer Rules 에 우리가 분류해야 할 토큰 규칙들이 위치한다. 자세한 것은 인터넷 검색을 통해 해결하도록 하자. flex 에 대한 것들을 자세히 설명하기보다 바로 예제를 통해 이해하도록 한다.

예를 들어 보자.


```
%{
#include <iostream>
#include <cstdlib>
#include "scanner.h"
using namespace std;
#define yyterminate() 0;
%}
%option nodefault
%option noyywrap
%option c++
%option yyclass="Scanner"
%option yylineno
%%
[a-z][a-z0-9]* { 
    std::cout << yytext << std::endl;
    return 11;
} 
[0-9][0-9]* {
    std::cout << yytext << std::endl;
    return 12;
} 
= {
    std::cout << yytext << std::endl;
    return 13;
} 
[\n\t ] {
} 
. { 
} 
<<EOF>> { 
    std::cout << "EOF" << std::endl;
    return yyterminate(); 
} 
%% 
```

%% 사이의 문법만 주목해서 보자. 정규식 { ... } 형태로 기술되는데, 블록{} 사이에는 C/C++ 코드가 들어갈 수 있다. 이 사이에 들어온 순간은 이미 렉서에 의해 토큰이 분류된 이후다. `apple 5543 hello world =` 입력된 문자열이 이와 같을 때 토큰 분류기는 `11 12 11 11 13` 과 같이 반환된다. 이렇게 토큰화를 통해 숫자형 배열에 담은 후 구문분석(Parsing)을 하게 된다. 

```
▾ tutorial1/
    main.cpp
    scanner.h
    scanner.l
```
```
$ cd tutorial1 
$ flex scanner.l && g++ lex.yy.cc main.cpp -std=c++11 && ./a.out 
```

일부러 흐름을 잘 보여주기 위해 당분간은 CMake 를 쓰지 않겠다. 컴파일 되는 흐름을 잘 이해해야 한다. 먼저 flex 명령어를 통해 lex.yy.cc 가 생긴다. lex.yy.cc 안에는 `%option yyclass="Scanner"` 에 의해 `YY_DECL` 매크로가 정의된다. 
```
// scanner.h
class Scanner : public yyFlexLexer {
    public:
        Scanner(std::istream *in) : yyFlexLexer(in) {} 
        virtual int yylex(); 
};

// lex.yy.cc
#define YY_DECL int Scanner::yylex() 
...
#include "scanner.h"
...
YY_DECL
{
	register yy_state_type yy_current_state;
	register char *yy_cp, *yy_bp;
	register int yy_act;
    ...
}
```

Scanner::yylex 가 overriding 으로 구현된다. 렉서파일에 scanner.h 를 쓰고 또 Scanner 클래스가 flex 를 쓰고, 생성된 파일(lex.yy.cc) 에서 scanner.h 를 쓰는 이상한 기분이지만 이 상호작용을 잘 이해하고 넘어가기 바란다.

```
// main.cpp
    std::istringstream is(R"(
    apple 5543 hello world =
    )"); 
    Scanner scanner(&is);
    while(1) {
        int t = scanner.yylex();
        if(t == 0) {
            break;
        }
        std::cout << t << std::endl;
    }

```

위 프로그램에 의해 flex 를 실행할 수 있다.

동작하는 예제는 github 주소 tutorial1 에 넣겠다. 




# 구문분석이란

![image](https://user-images.githubusercontent.com/3623889/72686221-9f4ab400-3b35-11ea-865d-307ef90669a3.png)

이전 장에서 토큰화가 무엇인지 알아봤다. 토큰화과정만으로는 우리가 할 수 있는 것이 거의 없다. 

위키 인용

>컴퓨터 과학에서 파싱((syntactic) parsing)은 일련의 문자열을 의미있는 토큰(token)으로 분해하고 이들로 이루어진 파스 트리(parse tree)를 만드는 과정을 말한다.

컴퓨터 과학에서 파싱((syntactic) parsing)은 일련의 문자열을 의미있는 토큰(token)으로 분해하고 이들로 이루어진 파스 트리(parse tree)를 만드는 과정을 말한다.

- 하향식 구문 분석(top-down parsing)
- 상향식 구문 분석(bottom-up parsing)
구문분석에는 정말 크게 분류하면 아래와 같은 방법이 있다. 이 중에서 우리는 가장 구현하기 쉬운 하향식 구문 분석을 선택하겠다.  

# 구문분석 하는 방법


처음부터 while 문 if 문 function 에 대해서 다루면 좋겠지만 컴파일러를 이제 막 만들어보고 싶다는 생각을 가졌다면 걷기는 커녕 기어다니기도 힘든 지경일거다. 파싱 구현에 대해 감을 가장 쉽게 잡을 수 있고, 제일 구현하기 쉬운 형태의 예제를 구현하면서 점차 절차지향적 프로그래밍에서 사용되는 while, if 문으로 확장할 것이다. 

# 1차 구문분석의 예제
간단한 수식을 입력 받아 계산된 결과를 보여주는 프로그램을 작성해본다.

`1 + 3 * 5 - 1 / 3 + 100 * 1`
`1 + (3 * 5 - 1) / 3 + 100 * 1`
`1 - (3 * 5 - 1) / 3 + 100 * 1`
`-(3 * 5 - 1)`

간단한 사칙연산을 지원하며 괄호() 문법을 지원하며 일반적인 사칙연산의 우선순위를 따르도록 한다. 




